{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'turku-ner-corpus']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(os.walk('.'))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perhe\\Miniconda3\\envs\\NLPCourse\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\perhe\\Miniconda3\\envs\\NLPCourse\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\perhe\\Miniconda3\\envs\\NLPCourse\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\perhe\\Miniconda3\\envs\\NLPCourse\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\perhe\\Miniconda3\\envs\\NLPCourse\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\perhe\\Miniconda3\\envs\\NLPCourse\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16801544846930107588\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3154483609\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1150077492823011657\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Test if tensorflow has access to GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and format\n",
    "\n",
    "The data is given in a .tsv format, which for some reason did not read nicely into pandas, so the following section is to read the data into a dataframe with sentenceID's (incremented) so we can easily access them as we wish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A hack function to increment sentenceID's in the dataframe\n",
    "def sentenceID(row: pd.Series) -> int:\n",
    "    global count\n",
    "    \n",
    "    if pd.isna(row[1]):\n",
    "        count += 1\n",
    "        return count\n",
    "    else:\n",
    "        return count \n",
    "    \n",
    "def dataframe_from_tsv(lines: [str]) -> pd.DataFrame:\n",
    "    train = pd.DataFrame(lines)                                                 # Create a dataframe for easier manipulation \n",
    "    train = train.drop(columns=[1])                                             # Drop the empty column\n",
    "    df = train[0].str.split('\\t', expand=True)                                  # Split by tab \n",
    "    df.columns = [\"Tokens\", \"Entities\"]                                         # Name columns \n",
    "    df['SentenceId'] = pd.Series('', index=[n for n in range(df.shape[0])])     # Append sentence column \n",
    "    df['SentenceId'] = df.apply(lambda row: sentenceID(row), axis=1)            # Append sentenceId by counts \n",
    "    df = df[~pd.isna(df['Entities'])]                                           # Drop empty rows \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('turku-ner-corpus/combined-extended/train.tsv', encoding='UTF-8') as file: \n",
    "    train_lines = [line.split('\\n') for line in file]\n",
    "    \n",
    "with open('turku-ner-corpus/combined-extended/dev.tsv', encoding='UTF-8') as file:\n",
    "    val_lines = [line.split('\\n') for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Tokens Entities  SentenceId\n",
      "0  Kävelyreitti        O           0\n",
      "1           III        O           0\n",
      "3        Jäällä        O           1\n",
      "4        kävely        O           1\n",
      "5          avaa        O           1\n",
      "       Tokens Entities  SentenceId\n",
      "0     Pelkkää        O           0\n",
      "1   tyhjyyttä        O           0\n",
      "3       Kävin        O           1\n",
      "4      tänään   B-DATE           1\n",
      "5  katsomassa        O           1\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "df_train = dataframe_from_tsv(train_lines)\n",
    "print(df_train.head())\n",
    "\n",
    "count = 0\n",
    "df_test = dataframe_from_tsv(val_lines)\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Entities</th>\n",
       "      <th>SentenceId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pelkkää</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tyhjyyttä</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kävin</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tänään</td>\n",
       "      <td>B-DATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>katsomassa</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Suomen</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Perinteisen</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Teatterin</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>näytelmän</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ranta</td>\n",
       "      <td>B-WORK_OF_ART</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tokens       Entities  SentenceId\n",
       "0       Pelkkää              O           0\n",
       "1     tyhjyyttä              O           0\n",
       "3         Kävin              O           1\n",
       "4        tänään         B-DATE           1\n",
       "5    katsomassa              O           1\n",
       "6        Suomen          B-ORG           1\n",
       "7   Perinteisen          I-ORG           1\n",
       "8     Teatterin          I-ORG           1\n",
       "9     näytelmän              O           1\n",
       "10        Ranta  B-WORK_OF_ART           1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_df(df: pd.DataFrame) -> (list, list): \n",
    "    texts = []\n",
    "    labels = []\n",
    "    for sent_id in range(max(df['SentenceId'].unique())):\n",
    "        temp_df = df.query(f\"SentenceId == {sent_id}\")\n",
    "        texts.append(temp_df['Tokens'].tolist())\n",
    "        labels.append(temp_df['Entities'].tolist())\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially in same format as in the course example\n",
    "train_texts, train_labels = unpack_df(df_train)\n",
    "validation_texts, validation_labels = unpack_df(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "====== TRAIN ========\n",
      "=====================\n",
      "Text: ['Kävelyreitti', 'III']\n",
      "Label: ['O', 'O']\n",
      "Text: ['Jäällä', 'kävely', 'avaa', 'aina', 'hauskoja', 'ja', 'erikoisia', 'näkökulmia', 'kaupunkiin', '.']\n",
      "Label: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Text: ['Vähän', 'samanlainen', 'tunne', 'kuin', 'silloin', ',', 'kun', 'ystävämme', 'vei', 'meidät', 'kerran', 'ylös', 'tuomiokirkon', 'torniin', '.']\n",
      "Label: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Text: ['Kuinka', 'erilaiselta', 'maailma', 'sieltä', 'näyttikään', '.']\n",
      "Label: ['O', 'O', 'O', 'O', 'O', 'O']\n",
      "Text: ['Vaikka', 'tiesi', ',', 'millainen', 'Turku', 'on', 'kartalla', ',', 'se', 'hämmästytti', 'siltikin', '.']\n",
      "Label: ['O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "=====================\n",
      "==== VALIDATION =====\n",
      "=====================\n",
      "Text: ['Pelkkää', 'tyhjyyttä']\n",
      "Label: ['O', 'O']\n",
      "Text: ['Kävin', 'tänään', 'katsomassa', 'Suomen', 'Perinteisen', 'Teatterin', 'näytelmän', 'Ranta', '.']\n",
      "Label: ['O', 'B-DATE', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-WORK_OF_ART', 'O']\n",
      "Text: ['Jo', 'teatterin', 'nimi', 'antikliimaksi', ';', 'ikäänkuin', 'ryhmä', 'tahtoisi', 'antaa', 'katsojalle', 'vakuutuksen', 'siitä', ',', 'ettei', 'mitään', 'tarvitse', 'ajatella', 'tahi', 'pohtia', '.']\n",
      "Label: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Text: ['Valitettavasti', 'esitys', 'oli', 'hyvin', 'pitkälle', 'sellainen', '.']\n",
      "Label: ['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Text: ['Lava', 'oli', 'tyhjä', 'yhtä', 'kevyttä', 'sohvaa', 'ja', 'paria', 'irtotuolia', 'lukuunottamatta', '.']\n",
      "Label: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(\"=====================\")\n",
    "print(\"====== TRAIN ========\")\n",
    "print(\"=====================\")\n",
    "# Sanity check. \n",
    "for n in range(5):\n",
    "    print('Text:', train_texts[n])\n",
    "    print('Label:', train_labels[n])\n",
    "print(\"=====================\")\n",
    "print(\"==== VALIDATION =====\")\n",
    "print(\"=====================\")\n",
    "# Sanity check. \n",
    "for n in range(5):\n",
    "    print('Text:', validation_texts[n])\n",
    "    print('Label:', validation_labels[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the word embeddings \n",
    "\n",
    "The following is mainly taken from the course material, except that the .vec file (for finnish word embeddings) is downloaded from fastText. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words from embedding model: 50000\n",
      "First 50 words: ['.', ',', 'ja', '</s>', 'on', ':', '\"', ')', '(', '/', \"'\", 'oli', 'ei', '–', 'että', '-', 'myös', '1', '!', 'tai', 'Lisätiedot', '?', 'ovat', 'mutta', 'joka', 'se', 'sekä', 'n', 'vuonna', '#', '2', '%', 'kun', 'hän', 'sen', 'ole', 'kuin', 'niin', '”', 'kanssa', 'voi', '...', '+', '3', '&', 'kello', 'Hän', 'mukaan', 'jälkeen', 'klo']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "vector_model = KeyedVectors.load_word2vec_format(\"cc.fi.300.vec\", binary=False, limit=50000)\n",
    "\n",
    "# sort based on the index to make sure they are in the correct order\n",
    "words = [k for k, v in sorted(vector_model.vocab.items(), key=lambda x: x[1].index)]\n",
    "print(\"Words from embedding model:\", len(words))\n",
    "print(\"First 50 words:\", words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization: [ 0.0686  0.0713 -0.0378 -0.1222 -0.0428 -0.1847  0.0278 -0.0429  0.4505\n",
      " -0.008 ]\n",
      "After normalization: [ 0.04610316  0.04791772 -0.02540378 -0.08212546 -0.02876407 -0.12412907\n",
      "  0.01868321 -0.02883128  0.30276206 -0.00537646]\n"
     ]
    }
   ],
   "source": [
    "# Normalize the vectors to unit length\n",
    "print(\"Before normalization:\", vector_model.get_vector(\"ja\")[:10])\n",
    "vector_model.init_sims(replace=True)\n",
    "print(\"After normalization:\", vector_model.get_vector(\"ja\")[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Todo: check the following code carefully -- does not necessarily work one-to-one from course example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in vocabulary: 50002\n",
      "Found pretrained vectors for 50000 words.\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary mappings\n",
    "\n",
    "# Zero is used for padding in Keras, prevent using it for a normal word.\n",
    "# Also reserve an index for out-of-vocabulary items.\n",
    "vocabulary={\n",
    "    \"<PAD>\": 0,\n",
    "    \"<OOV>\": 1\n",
    "}\n",
    "\n",
    "for word in words: # These are words from the word2vec model\n",
    "    vocabulary.setdefault(word, len(vocabulary))\n",
    "\n",
    "print(\"Words in vocabulary:\",len(vocabulary))\n",
    "inv_vocabulary = { value: key for key, value in vocabulary.items() } # invert the dictionary\n",
    "\n",
    "\n",
    "# Embedding matrix\n",
    "# Loads word embeddings into an array. \n",
    "def load_pretrained_embeddings(vocab, embedding_model):\n",
    "    \"\"\" vocab: vocabulary from our data vectorizer, embedding_model: model loaded with gensim \"\"\"\n",
    "    pretrained_embeddings = np.random.uniform(low=-0.05, high=0.05, size=(len(vocab)-1,embedding_model.vectors.shape[1]))\n",
    "    pretrained_embeddings = np.vstack((np.zeros(shape=(1,embedding_model.vectors.shape[1])), pretrained_embeddings))\n",
    "    found=0\n",
    "    for word,idx in vocab.items():\n",
    "        if word in embedding_model.vocab:\n",
    "            pretrained_embeddings[idx]=embedding_model.get_vector(word)\n",
    "            found+=1\n",
    "            \n",
    "    print(\"Found pretrained vectors for {found} words.\".format(found=found))\n",
    "    return pretrained_embeddings\n",
    "\n",
    "pretrained=load_pretrained_embeddings(vocabulary, vector_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-DATE': 30,\n",
      " 'B-EVENT': 17,\n",
      " 'B-FAC': 14,\n",
      " 'B-GPE': 21,\n",
      " 'B-LANGUAGE': 29,\n",
      " 'B-LAW': 26,\n",
      " 'B-LOC': 12,\n",
      " 'B-MONEY': 22,\n",
      " 'B-NORP': 24,\n",
      " 'B-ORG': 3,\n",
      " 'B-PERCENT': 25,\n",
      " 'B-PERSON': 23,\n",
      " 'B-PRODUCT': 8,\n",
      " 'B-QUANTITY': 31,\n",
      " 'B-TIME': 32,\n",
      " 'B-WORK_OF_ART': 7,\n",
      " 'I-DATE': 27,\n",
      " 'I-EVENT': 4,\n",
      " 'I-FAC': 5,\n",
      " 'I-GPE': 16,\n",
      " 'I-LANGUAGE': 19,\n",
      " 'I-LAW': 0,\n",
      " 'I-LOC': 11,\n",
      " 'I-MONEY': 18,\n",
      " 'I-NORP': 2,\n",
      " 'I-ORG': 20,\n",
      " 'I-PERCENT': 1,\n",
      " 'I-PERSON': 6,\n",
      " 'I-PRODUCT': 9,\n",
      " 'I-QUANTITY': 15,\n",
      " 'I-TIME': 28,\n",
      " 'I-WORK_OF_ART': 13,\n",
      " 'O': 10}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Label mappings\n",
    "# 1) gather a set of unique labels\n",
    "label_set = set()\n",
    "for sentence_labels in train_labels: #loops over sentences\n",
    "    for label in sentence_labels: #loops over labels in one sentence\n",
    "        label_set.add(label)\n",
    "\n",
    "# 2) index these\n",
    "label_map = {}\n",
    "for index, label in enumerate(label_set):\n",
    "    label_map[label]=index\n",
    "    \n",
    "pprint(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10]\n"
     ]
    }
   ],
   "source": [
    "# vectorize the labels\n",
    "def label_vectorizer(labels,label_map):\n",
    "    vectorized_labels = []\n",
    "    for label in labels:\n",
    "        vectorized_example_label = []\n",
    "        for token in label:\n",
    "            vectorized_example_label.append(label_map[token])\n",
    "        vectorized_labels.append(vectorized_example_label)\n",
    "    vectorized_labels = np.array(vectorized_labels)\n",
    "    return vectorized_labels\n",
    "        \n",
    "vectorized_labels = label_vectorizer(train_labels, label_map)\n",
    "validation_vectorized_labels = label_vectorizer(validation_labels, label_map)\n",
    "\n",
    "pprint(vectorized_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kävelyreitti', 'III']\n",
      "[1, 922]\n",
      "['<OOV>', 'III']\n"
     ]
    }
   ],
   "source": [
    "def text_vectorizer(vocab, texts):\n",
    "    vectorized_data = [] # turn text into numbers based on our vocabulary mapping\n",
    "    sentence_lengths = [] # Number of tokens in each sentence\n",
    "    \n",
    "    for i, one_example in enumerate(texts):\n",
    "        vectorized_example = []\n",
    "        for word in one_example:\n",
    "            vectorized_example.append(vocab.get(word, 1)) # 1 is our index for out-of-vocabulary tokens\n",
    "\n",
    "        vectorized_data.append(vectorized_example)     \n",
    "        sentence_lengths.append(len(one_example))\n",
    "        \n",
    "    vectorized_data = np.array(vectorized_data) # turn python list into numpy array\n",
    "    \n",
    "    return vectorized_data, sentence_lengths\n",
    "\n",
    "vectorized_data, lengths=text_vectorizer(vocabulary, train_texts)\n",
    "validation_vectorized_data, validation_lengths=text_vectorizer(vocabulary, validation_texts)\n",
    "\n",
    "sent = 0\n",
    "print(train_texts[sent])\n",
    "print(vectorized_data[sent])\n",
    "print([inv_vocabulary[i] for i in vectorized_data[sent]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old shape: (27832,)\n",
      "New shape: (27832, 274)\n",
      "First example: [  1 922   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0]\n",
      "Padded labels shape: (27832, 274, 1)\n",
      "{'B-DATE': 30,\n",
      " 'B-EVENT': 17,\n",
      " 'B-FAC': 14,\n",
      " 'B-GPE': 21,\n",
      " 'B-LANGUAGE': 29,\n",
      " 'B-LAW': 26,\n",
      " 'B-LOC': 12,\n",
      " 'B-MONEY': 22,\n",
      " 'B-NORP': 24,\n",
      " 'B-ORG': 3,\n",
      " 'B-PERCENT': 25,\n",
      " 'B-PERSON': 23,\n",
      " 'B-PRODUCT': 8,\n",
      " 'B-QUANTITY': 31,\n",
      " 'B-TIME': 32,\n",
      " 'B-WORK_OF_ART': 7,\n",
      " 'I-DATE': 27,\n",
      " 'I-EVENT': 4,\n",
      " 'I-FAC': 5,\n",
      " 'I-GPE': 16,\n",
      " 'I-LANGUAGE': 19,\n",
      " 'I-LAW': 0,\n",
      " 'I-LOC': 11,\n",
      " 'I-MONEY': 18,\n",
      " 'I-NORP': 2,\n",
      " 'I-ORG': 20,\n",
      " 'I-PERCENT': 1,\n",
      " 'I-PERSON': 6,\n",
      " 'I-PRODUCT': 9,\n",
      " 'I-QUANTITY': 15,\n",
      " 'I-TIME': 28,\n",
      " 'I-WORK_OF_ART': 13,\n",
      " 'O': 10}\n",
      "First example labels:\n",
      "array([[10],\n",
      "       [10],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0]])\n",
      "First weight vector: [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(\"Old shape:\", vectorized_data.shape)\n",
    "vectorized_data_padded=pad_sequences(vectorized_data, padding='post', maxlen=max(lengths))\n",
    "print(\"New shape:\", vectorized_data_padded.shape)\n",
    "print(\"First example:\", vectorized_data_padded[0])\n",
    "\n",
    "# Even with the sparse output format, the shape has to be similar to the one-hot encoding\n",
    "vectorized_labels_padded=np.expand_dims(pad_sequences(vectorized_labels, padding='post', maxlen=max(lengths)), -1)\n",
    "print(\"Padded labels shape:\", vectorized_labels_padded.shape)\n",
    "pprint(label_map)\n",
    "print(\"First example labels:\")\n",
    "pprint(vectorized_labels_padded[0])\n",
    "\n",
    "weights = np.copy(vectorized_data_padded)\n",
    "weights[weights > 0] = 1\n",
    "print(\"First weight vector:\", weights[0])\n",
    "\n",
    "# Same stuff for the validation data\n",
    "validation_vectorized_data_padded=pad_sequences(validation_vectorized_data, padding='post', maxlen=max(lengths))\n",
    "validation_vectorized_labels_padded=np.expand_dims(pad_sequences(validation_vectorized_labels, padding='post',maxlen=max(lengths)), -1)\n",
    "validation_weights = np.copy(validation_vectorized_data_padded)\n",
    "validation_weights[validation_weights > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def _convert_to_entities(input_sequence):\n",
    "    \"\"\"\n",
    "    Reads a sequence of tags and converts them into a set of entities.\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    current_entity = []\n",
    "    previous_tag = label_map['O']\n",
    "    for i, tag in enumerate(input_sequence):\n",
    "        if tag != previous_tag and tag != label_map['O']: # New entity starts\n",
    "            if len(current_entity) > 0:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = []\n",
    "            current_entity.append((tag, i))\n",
    "        elif tag == label_map['O']: # Entity has ended\n",
    "            if len(current_entity) > 0:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = []\n",
    "        elif tag == previous_tag: # Current entity continues\n",
    "            current_entity.append((tag, i))\n",
    "        previous_tag = tag\n",
    "    \n",
    "    # Add the last entity to our entity list if the sentences ends with an entity\n",
    "    if len(current_entity) > 0:\n",
    "        entities.append(current_entity)\n",
    "    \n",
    "    entity_offsets = set()\n",
    "    \n",
    "    for e in entities:\n",
    "        entity_offsets.add((e[0][0], e[0][1], e[-1][1]+1))\n",
    "    return entity_offsets\n",
    "\n",
    "\n",
    "def _entity_level_PRF(predictions, gold, lengths):\n",
    "    pred_entities = [_convert_to_entities(labels[:lengths[i]]) for i, labels in enumerate(predictions)]\n",
    "    gold_entities = [_convert_to_entities(labels[:lengths[i], 0]) for i, labels in enumerate(gold)]\n",
    "    \n",
    "    tp = sum([len(pe.intersection(gold_entities[i])) for i, pe in enumerate(pred_entities)])\n",
    "    pred_count = sum([len(e) for e in pred_entities])\n",
    "    \n",
    "    try:\n",
    "        precision = tp / pred_count # tp / (tp+np)\n",
    "        recall = tp / sum([len(e) for e in gold_entities])\n",
    "        fscore = 2 * precision * recall / (precision + recall)\n",
    "    except Exception as e:\n",
    "        precision, recall, fscore = 0.0, 0.0, 0.0\n",
    "    print('\\nPrecision/Recall/F-score: %s / %s / %s' % (precision, recall, fscore))\n",
    "    return precision, recall, fscore             \n",
    "\n",
    "\n",
    "def evaluate(predictions, gold, lengths):\n",
    "    precision, recall, fscore = _entity_level_PRF(predictions, gold, lengths)\n",
    "    return precision, recall, fscore\n",
    "\n",
    "\n",
    "class EvaluateEntities(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.precision = []\n",
    "        self.recall = []\n",
    "        self.fscore = []\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        pred = np.argmax(self.model.predict(validation_vectorized_data_padded), axis=-1)\n",
    "        evaluation_parameters=evaluate(pred, validation_vectorized_labels_padded, validation_lengths)\n",
    "        self.precision.append(evaluation_parameters[0])\n",
    "        self.recall.append(evaluation_parameters[1])\n",
    "        self.fscore.append(evaluation_parameters[2])\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Activation, TimeDistributed\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "\n",
    "example_count, sequence_len = vectorized_data_padded.shape\n",
    "class_count = len(label_set)\n",
    "hidden_size = 100\n",
    "\n",
    "vector_size= pretrained.shape[1]\n",
    "\n",
    "\n",
    "def build_model(example_count, sequence_len, class_count, hidden_size, vocabulary, vector_size, pretrained):\n",
    "    inp=Input(shape=(sequence_len,))\n",
    "    embeddings=Embedding(len(vocabulary), vector_size, mask_zero=True, trainable=False, weights=[pretrained])(inp)\n",
    "    hidden = TimeDistributed(Dense(hidden_size, activation=\"relu\"))(embeddings) # We change this activation function\n",
    "    outp = TimeDistributed(Dense(class_count, activation=\"softmax\"))(hidden)\n",
    "    return Model(inputs=[inp], outputs=[outp])\n",
    "\n",
    "model = build_model(example_count, sequence_len, class_count, hidden_size, vocabulary, vector_size, pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 274)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 274, 300)          15000600  \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 274, 100)          30100     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 274, 33)           3333      \n",
      "=================================================================\n",
      "Total params: 15,034,033\n",
      "Trainable params: 33,433\n",
      "Non-trainable params: 15,000,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Precision/Recall/F-score: 0.467843631778058 / 0.1727992547741034 / 0.2523809523809524\n",
      " - 5s - loss: 1.0672\n",
      "Epoch 2/10\n",
      "\n",
      "Precision/Recall/F-score: 0.49341842840047867 / 0.28807638565440147 / 0.36377003381855616\n",
      " - 3s - loss: 0.5254\n",
      "Epoch 3/10\n",
      "\n",
      "Precision/Recall/F-score: 0.5017103762827823 / 0.3074056823474616 / 0.3812274368231047\n",
      " - 3s - loss: 0.4791\n",
      "Epoch 4/10\n",
      "\n",
      "Precision/Recall/F-score: 0.5063752276867031 / 0.32370749883558453 / 0.39494246341809913\n",
      " - 3s - loss: 0.4603\n",
      "Epoch 5/10\n",
      "\n",
      "Precision/Recall/F-score: 0.5162314749470712 / 0.3407079646017699 / 0.41049382716049376\n",
      " - 3s - loss: 0.4503\n",
      "Epoch 6/10\n",
      "\n",
      "Precision/Recall/F-score: 0.5190053285968028 / 0.34024219841639497 / 0.41102827401884934\n",
      " - 3s - loss: 0.4443\n",
      "Epoch 7/10\n",
      "\n",
      "Precision/Recall/F-score: 0.5177824267782427 / 0.3458313926408943 / 0.41468863445964815\n",
      " - 3s - loss: 0.4398\n",
      "Epoch 8/10\n",
      "\n",
      "Precision/Recall/F-score: 0.5298747763864043 / 0.3448998602701444 / 0.4178304415291297\n",
      " - 3s - loss: 0.4361\n",
      "Epoch 9/10\n",
      "\n",
      "Precision/Recall/F-score: 0.5261115031757233 / 0.3472286911970191 / 0.41835016835016836\n",
      " - 3s - loss: 0.4331\n",
      "Epoch 10/10\n",
      "\n",
      "Precision/Recall/F-score: 0.5222885222885223 / 0.3465300419189567 / 0.4166316673666527\n",
      " - 3s - loss: 0.4308\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=0.001) # define the learning rate\n",
    "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", sample_weight_mode='temporal')\n",
    "evaluation_function=EvaluateEntities()\n",
    "\n",
    "# train\n",
    "vanilla_hist=model.fit(\n",
    "    vectorized_data_padded,\n",
    "    vectorized_labels_padded,\n",
    "    sample_weight=weights,\n",
    "    batch_size=100,\n",
    "    verbose=2,\n",
    "    epochs=10,\n",
    "    callbacks=[evaluation_function]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History: [0.2523809523809524, 0.36377003381855616, 0.3812274368231047, 0.39494246341809913, 0.41049382716049376, 0.41102827401884934, 0.41468863445964815, 0.4178304415291297, 0.41835016835016836, 0.4166316673666527]\n",
      "Highest f-score: 0.41835016835016836\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(fscores):\n",
    "    print(\"History:\", fscores)\n",
    "    print(\"Highest f-score:\", max(fscores))\n",
    "    plt.plot(fscores)\n",
    "    plt.legend(loc='lower center', borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(evaluation_function.fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 274)               0         \n",
      "_________________________________________________________________\n",
      "embedding_13 (Embedding)     (None, 274, 300)          15000600  \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 274, 100)          120300    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 274, 33)           3333      \n",
      "=================================================================\n",
      "Total params: 15,124,233\n",
      "Trainable params: 123,633\n",
      "Non-trainable params: 15,000,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "\n",
    "\n",
    "example_count, sequence_len = vectorized_data_padded.shape\n",
    "class_count = len(label_set)\n",
    "rnn_size = 100\n",
    "\n",
    "vector_size= pretrained.shape[1]\n",
    "\n",
    "\n",
    "def build_rnn_model(example_count, sequence_len, class_count, rnn_size, vocabulary, vector_size, pretrained):\n",
    "    inp=Input(shape=(sequence_len,))\n",
    "    embeddings=Embedding(len(vocabulary), vector_size, mask_zero=True, trainable=False, weights=[pretrained])(inp)\n",
    "    rnn = GRU(rnn_size, activation='relu', return_sequences=True)(embeddings)\n",
    "    #rnn = LSTM(rnn_size, activation='relu', return_sequences=True)(embeddings)\n",
    "    outp = Dense(class_count, activation=\"softmax\")(rnn)\n",
    "    return Model(inputs=[inp], outputs=[outp])\n",
    "\n",
    "rnn_model = build_rnn_model(example_count, sequence_len, class_count, rnn_size, vocabulary, vector_size, pretrained)\n",
    "\n",
    "print(rnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Precision/Recall/F-score: 0.4129277566539924 / 0.1264555193292967 / 0.19361740060616867\n",
      " - 191s - loss: 1.0585\n",
      "Epoch 2/10\n",
      "\n",
      "Precision/Recall/F-score: 0.5717703349282297 / 0.3896134140661388 / 0.4634349030470914\n",
      " - 184s - loss: 0.4639\n",
      "Epoch 3/10\n",
      "\n",
      "Precision/Recall/F-score: 0.6216393442622951 / 0.4415463437354448 / 0.5163398692810457\n",
      " - 184s - loss: 0.3756\n",
      "Epoch 4/10\n",
      "\n",
      "Precision/Recall/F-score: 0.6650132275132276 / 0.468327899394504 / 0.5496037168625307\n",
      " - 182s - loss: 0.3401\n",
      "Epoch 5/10\n",
      "\n",
      "Precision/Recall/F-score: 0.6905396402398402 / 0.48276665114112716 / 0.5682565789473685\n",
      " - 190s - loss: 0.3202\n",
      "Epoch 6/10\n",
      "\n",
      "Precision/Recall/F-score: 0.6863905325443787 / 0.5132743362831859 / 0.5873417721518988\n",
      " - 176s - loss: 0.3053\n",
      "Epoch 7/10\n",
      "\n",
      "Precision/Recall/F-score: 0.6988294843403986 / 0.5144387517466232 / 0.5926224010731054\n",
      " - 173s - loss: 0.2946\n",
      "Epoch 8/10\n",
      "\n",
      "Precision/Recall/F-score: 0.6959975557592423 / 0.5305076851420587 / 0.6020880137438879\n",
      " - 176s - loss: 0.2850\n",
      "Epoch 9/10\n",
      "\n",
      "Precision/Recall/F-score: 0.7212848799480857 / 0.5176991150442478 / 0.6027657266811279\n",
      " - 174s - loss: 0.2782\n",
      "Epoch 10/10\n",
      "\n",
      "Precision/Recall/F-score: 0.6946811636791067 / 0.5505356311131812 / 0.6142652981681175\n",
      " - 186s - loss: 0.2710\n"
     ]
    }
   ],
   "source": [
    "optimizer=Adam(lr=0.001) # define the learning rate\n",
    "rnn_model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\", sample_weight_mode='temporal')\n",
    "\n",
    "evaluation_function=EvaluateEntities()\n",
    "\n",
    "# train\n",
    "rnn_hist=rnn_model.fit(vectorized_data_padded,vectorized_labels_padded, sample_weight=weights, batch_size=100,verbose=2,epochs=10, callbacks=[evaluation_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History: [0.19361740060616867, 0.4634349030470914, 0.5163398692810457, 0.5496037168625307, 0.5682565789473685, 0.5873417721518988, 0.5926224010731054, 0.6020880137438879, 0.6027657266811279, 0.6142652981681175]\n",
      "Highest f-score: 0.6142652981681175\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(evaluation_function.fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('gru_lr_0.001_catcrossentropy_f_0.614.h5')\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "# model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPCourse",
   "language": "python",
   "name": "nlpcourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
